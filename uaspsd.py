# -*- coding: utf-8 -*-
"""uaspsd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UY0p_Jfo-P3RtJg33CtpJxcl5NFQmIEm

Isnain Faiziah (200411100007)

Nella Adrisia Hartono (200411100107)
"""

# !pip install pandas
# !pip install numpy

import math
import matplotlib.pyplot as plt
import keras
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
from keras.layers import *
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from keras.callbacks import EarlyStopping

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("https://raw.githubusercontent.com/nellaadrs/kelompokpro-1/main/SMGR.JK.csv")
df

df.plot(x='Date', y ='Volume')

training_set = df.iloc[:197, 1:-1].values
test_set = df.iloc[49:, 1:-1].values

from numpy import array

# split a univariate sequence into samples
def split_sequence(sequence, n_steps):
	X, y = list(), list()
	for i in range(len(sequence)):
		# find the end of this pattern
		end_ix = i + n_steps
		# check if we are beyond the sequence
		if end_ix > len(sequence)-1:
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)

# Feature Scaling
sc = MinMaxScaler(feature_range = (0, 1))
training_set_scaled = sc.fit_transform(training_set)
# Creating a data structure with 60 time-steps and 1 output
X_train = []
y_train = []
x = 5
for i in range(x, 197):
    X_train.append(training_set_scaled[i-x:i, 0])
    y_train.append(training_set_scaled[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
#(740, 60, 1)

xtrainbaru = np.reshape(X_train, (192, 5))

xtrainbaru

from sklearn.neighbors import KNeighborsRegressor
neigh = KNeighborsRegressor(n_neighbors=3)
modelknn=neigh.fit(xtrainbaru, y_train)

# Definisikan dataset_train dan dataset_test
dataset_train = df.iloc[:197, 1:2]  # Menggunakan 45 baris pertama sebagai data latihan
dataset_test = df.iloc[49:, 1:2]  # Menggunakan baris setelah 45 sebagai data uji

# Menggabungkan dataset_train dan dataset_test
dataset_total = pd.concat([dataset_train, dataset_test], axis=0)

# Mengambil input dari dataset_total
inputs = dataset_total[len(dataset_total) - len(dataset_test) - 5:].values

inputs = inputs.reshape(-1,1)

inputs =sc.fit_transform(inputs)
X_test = []
for i in range(5, 24):
    X_test.append(inputs[i-5:i, 0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
print(X_test.shape)

xtestbaru = np.reshape(X_test, (19, 5))

predicted_pass = modelknn.predict(xtestbaru)

predicted_pass = predicted_pass.reshape(-1,1)
prediksi= sc.inverse_transform(predicted_pass)
dataset_test=dataset_test.iloc[0:19]

from sklearn.metrics import mean_absolute_percentage_error

mean_absolute_percentage_error(dataset_test, prediksi)

from sklearn.svm import SVR
svm = SVR(kernel='rbf')
model=svm.fit(xtrainbaru, y_train)
# Definisikan dataset_train dan dataset_test
dataset_train = df.iloc[:197, 1:2]  # Menggunakan 45 baris pertama sebagai data latihan
dataset_test = df.iloc[49:, 1:2]  # Menggunakan baris setelah 45 sebagai data uji
# Menggabungkan dataset_train dan dataset_test
dataset_total = pd.concat([dataset_train, dataset_test], axis=0)

#Mengambil input dari dataset_total
inputs = dataset_total[len(dataset_total) - len(dataset_test) - 5:].values
inputs = inputs.reshape(-1,1)
xtestbaru = np.reshape(X_test, (19, 5))
inputs =sc.fit_transform(inputs)
X_test = []
for i in range(5, 24):
    X_test.append(inputs[i-5:i, 0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
print(X_test.shape)

xtestbaru = np.reshape(X_test, (19, 5))
predicted_pass = model.predict(xtestbaru)

predicted_pass = predicted_pass.reshape(-1,1)
prediksi= sc.inverse_transform(predicted_pass)
dataset_test=dataset_test.iloc[0:19]
from sklearn.metrics import mean_absolute_percentage_error

mean_absolute_percentage_error(dataset_test, prediksi)
